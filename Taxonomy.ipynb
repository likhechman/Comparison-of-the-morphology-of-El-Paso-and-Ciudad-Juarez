{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a307bd75",
   "metadata": {},
   "source": [
    "# Numerical Taxonomy of Urban Form in El-Paso and Ciudad-Juares\n",
    "\n",
    "This notebook serves as a simplify template for morphometric assessment and generation of a taxonomy.\n",
    "\n",
    "## Reproducible Python code to generate taxonomy\n",
    "\n",
    "Complete morphometrics assessment from input data to taxonomy.\n",
    "\n",
    "Input data:\n",
    " - building footprints\n",
    " - street network\n",
    " \n",
    "This notebook is running the analysis on the sample of the data used in El-Paso and Ciudad-Juares case study. You can replace the sample with your own data, assuming that they are cleaned to a required standard. \n",
    "\n",
    "The sample is saved in `../data/data.gpkg` with two layers named `buildings` and `streets`. `buildings` are Polygons, whilst `streets` are LineStrings. They don't have any additonal attribuets.\n",
    "\n",
    "All data generated throughout the method are saved to files (unless commented out).\n",
    "\n",
    "This work demand at least 128GB RAM and 12GB of storage.\n",
    "\n",
    "First we import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import libpysal\n",
    "import mapclassify\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy as mm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# we are using bleeding edge software that emits some warnings irrelevant for the current runtime\n",
    "warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "warnings.filterwarnings('ignore', message='.*overflow encountered*')\n",
    "warnings.filterwarnings('ignore', message='.*index_parts defaults to True')\n",
    "warnings.filterwarnings('ignore', message='.*`op` parameter is deprecated*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8c01a",
   "metadata": {},
   "source": [
    "### Check the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa50df0",
   "metadata": {},
   "source": [
    "We load buildings and create unique ID and change crs if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/data.gpkg\"\n",
    "layer = \"buildings\"\n",
    "buildings = gpd.read_file(path, layer=layer)\n",
    "buildings = buildings.to_crs(crs=3857)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0120fa3",
   "metadata": {},
   "source": [
    "Let's create a persistent unique identifier for each building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfa4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"uID\"] = range(len(buildings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09564895",
   "metadata": {},
   "source": [
    "### Generate additional morphometric elements\n",
    "\n",
    "Before we can start morhometrics we have to generate additional elements - tessellation and tessellation based blocks.\n",
    "\n",
    "#### Morphological tessellation\n",
    "\n",
    "Check input for tessellation. If the input data is clean, the check will result in zeros. The data does not have to be 100% clean (all 0). For example `Split features` may not cause any issue. The function `mm.preprocess` allows you to eliminate some problems with geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68051de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = mm.CheckTessellationInput(buildings)\n",
    "buildings = mm.preprocess(buildings.reset_index(drop=True), size=10, compactness=0.2, loops=2, islands=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb21c77",
   "metadata": {},
   "source": [
    "Generate tessellation limited to 100 m buffer. Beware, it is memory demanding.\n",
    "\n",
    "**Note:** Code is adaptated for enclosed tessellation. You can do other method which requires more memory (more than 180GB for the study). In that case, you may consider using an [morphological tessellation](https://docs.momepy.org/en/stable/user_guide/elements/tessellation.html) method instead. However, that would require minor adaptation of the code below as well.\n",
    "\n",
    "First we need to import streets and change crs if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e86397",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = gpd.read_file(path, layer='streets')\n",
    "streets = streets.to_crs(crs=3857)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e092e3",
   "metadata": {},
   "source": [
    "Creating enclosures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31def862",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = mm.buffered_limit(buildings, 100)\n",
    "enclosures = mm.enclosures(streets, limit=gpd.GeoSeries([limit]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160cc3f",
   "metadata": {},
   "source": [
    "Creating tessellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = mm.Tessellation(buildings, unique_id='uID', enclosures=enclosures)\n",
    "tessellation = tessellation.tessellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe62e49",
   "metadata": {},
   "source": [
    "We save tessellation to file. Note that this file is not part of the repository but can be fully created using the input sample and this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.to_file(\"../data/geometry.gpkg\", layer=\"tessellation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019367a",
   "metadata": {},
   "source": [
    "### Link streets\n",
    "\n",
    "We need to understand which building belongs to which street segment. We link IDs together based on proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38261861",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"nID\"] = range(len(streets))\n",
    "buildings['nID'] = mm.get_network_id(buildings, streets, 'nID', min_size=300, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c12828",
   "metadata": {},
   "source": [
    "### Repair data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c6ce1",
   "metadata": {},
   "source": [
    "Drop null nIDs in buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e70de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.dropna(subset=['nID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622b8ab",
   "metadata": {},
   "source": [
    "Drop unnecessary elements in `buildings` and `tessellation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation.explode().drop_duplicates(subset=['uID'])\n",
    "\n",
    "buildings = buildings.merge(tessellation[['uID']], on='uID', how='inner')\n",
    "tessellation = tessellation.merge(buildings[['uID', 'nID']], on='uID', how='inner')\n",
    "\n",
    "buildings = buildings.drop_duplicates(subset='uID')\n",
    "tessellation = tessellation.drop_duplicates(subset='uID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962e294",
   "metadata": {},
   "source": [
    "Check if lengths of both frames is equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87df17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tessellation))\n",
    "print(len(buildings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d89a15",
   "metadata": {},
   "source": [
    "Finally, we save elements to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9982ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/geometry.gpkg'\n",
    "tessellation.to_file(path, layer='tessellation', driver='GPKG')\n",
    "buildings.to_file(path, layer='buildings', driver='GPKG')\n",
    "streets.to_file(path, layer='streets', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a64a4",
   "metadata": {},
   "source": [
    "### Creating blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe17bf",
   "metadata": {},
   "source": [
    "To create blocks within the full limit, it is always safer to extend street network to the edge of the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = mm.extend_lines(streets, tolerance=120, target=gpd.GeoSeries([limit.boundary]), barrier=buildings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722455d4",
   "metadata": {},
   "source": [
    "If you are confident in your data, you can simply create blocks by using `mm.Blocks` class which is commented below. But I will recomend doing it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a546fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocks = mm.Blocks(tessellation, edges=extended, buildings=buildings, id_name='bID', unique_id='uID')\n",
    "#blocks_df = blocks.blocks\n",
    "#buildings['bID'] = blocks.buildings_id.values\n",
    "#tessellation['bID'] = blocks.tessellation_id.values \n",
    "\n",
    "#blocks = blocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625ca38",
   "metadata": {},
   "source": [
    "Manual method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51583ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = gpd.overlay(tessellation, gpd.GeoDataFrame(geometry=extended.buffer(0.001)), how=\"difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = cut.explode(ignore_index=True)\n",
    "weights = libpysal.weights.Queen.from_dataframe(cut, silence_warnings=True)\n",
    "\n",
    "cut[\"component\"] = weights.component_labels\n",
    "buildings_c = buildings.copy()\n",
    "buildings_c.geometry = buildings_c.representative_point()  # make points\n",
    "\n",
    "centroids_temp_id = gpd.sjoin(\n",
    "        buildings_c,\n",
    "        cut[[cut.geometry.name, \"component\"]],\n",
    "        how=\"left\",\n",
    "        predicate=\"within\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_copy = tessellation[['uID', tessellation.geometry.name]].merge(centroids_temp_id[['uID', \"component\"]], on='uID', how=\"left\")\n",
    "blocks = cells_copy.dissolve(by=\"component\").explode(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0081fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks['bID'] = range(len(blocks))\n",
    "blocks = blocks[['bID', blocks.geometry.name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd22819",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_w_bl_id2 = gpd.sjoin(buildings_c, blocks, how=\"left\", predicate=\"within\")\n",
    "buildings_id = centroids_w_bl_id2['bID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_m = tessellation[['uID']].merge(centroids_w_bl_id2[['uID', 'bID']], on='uID', how=\"left\")\n",
    "cells_m = cells_m.drop_duplicates(subset='uID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.merge(cells_m[['uID', 'bID']], on='uID', how='left')\n",
    "tessellation = tessellation.merge(cells_m[['uID', 'bID']], on='uID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a80cb5",
   "metadata": {},
   "source": [
    "Save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ec9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.to_file(path, layer='tessellation', driver='GPKG')\n",
    "buildings.to_file(path, layer='buildings', driver='GPKG')\n",
    "streets.to_file(path, layer='streets', driver='GPKG')\n",
    "blocks.to_file(path, layer='blocks', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813a511",
   "metadata": {},
   "source": [
    "### Creating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_1 = libpysal.weights.contiguity.Queen.from_dataframe(tessellation, ids=\"uID\", silence_warnings=True)\n",
    "buildings_q1 = libpysal.weights.contiguity.Queen.from_dataframe(buildings, silence_warnings=True)\n",
    "blo_q1 = libpysal.weights.contiguity.Queen.from_dataframe(blocks, ids=\"bID\", silence_warnings=True)\n",
    "queen_3 = mm.sw_high(k=3, weights=queen_1)\n",
    "str_q1 = libpysal.weights.contiguity.Queen.from_dataframe(streets, silence_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc74df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "\n",
    "fo = libpysal.io.open(path+'queen_1.gal', 'w')\n",
    "fo.write(queen_1)\n",
    "fo.close()\n",
    "\n",
    "fo = libpysal.io.open(path+'buildings_q1.gal', 'w')\n",
    "fo.write(buildings_q1)\n",
    "fo.close()\n",
    "\n",
    "fo = libpysal.io.open(path+'blo_q1.gal', 'w')\n",
    "fo.write(blo_q1)\n",
    "fo.close()\n",
    "\n",
    "fo = libpysal.io.open(path+'queen_3.gal', 'w')\n",
    "fo.write(queen_3)\n",
    "fo.close()\n",
    "\n",
    "fo = libpysal.io.open(path+'str_q1.gal', 'w')\n",
    "fo.write(str_q1)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d5a49",
   "metadata": {},
   "source": [
    "## Measure primary characters\n",
    "\n",
    "This part measures 55 primary morphometric characters.\n",
    "\n",
    "It does save intermediate parquet files as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['sdbAre'] = mm.Area(buildings).series\n",
    "buildings['sdbPer'] = mm.Perimeter(buildings).series\n",
    "buildings['sdbCoA'] = mm.CourtyardArea(buildings, 'sdbAre').series\n",
    "\n",
    "buildings['ssbCCo'] = mm.CircularCompactness(buildings, 'sdbAre').series\n",
    "buildings['ssbCor'] = mm.Corners(buildings, verbose=False).series\n",
    "buildings['ssbSqu'] = mm.Squareness(buildings, verbose=False).series\n",
    "buildings['ssbERI'] = mm.EquivalentRectangularIndex(buildings, 'sdbAre', 'sdbPer').series\n",
    "buildings['ssbElo'] = mm.Elongation(buildings).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cencon = mm.CentroidCorners(buildings, verbose=False)\n",
    "buildings['ssbCCM'] = cencon.mean\n",
    "buildings['ssbCCD'] = cencon.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df683d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['stbOri'] = mm.Orientation(buildings, verbose=False).series\n",
    "tessellation['stcOri'] = mm.Orientation(tessellation, verbose=False).series\n",
    "\n",
    "buildings['stbCeA'] = mm.CellAlignment(buildings, tessellation, 'stbOri', 'stcOri', 'uID', 'uID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e72493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation['sdcLAL'] = mm.LongestAxisLength(tessellation).series\n",
    "tessellation['sdcAre'] = mm.Area(tessellation).series\n",
    "tessellation['sscCCo'] = mm.CircularCompactness(tessellation, 'sdcAre').series\n",
    "tessellation['sscERI'] = mm.EquivalentRectangularIndex(tessellation, 'sdcAre').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"libNCo\"] = mm.Courtyards(buildings, spatial_weights=buildings_q1, verbose=False).series\n",
    "buildings[\"ldbPWL\"] = mm.PerimeterWall(buildings, buildings_q1, verbose=False).series\n",
    "\n",
    "blocks[\"ldkAre\"] = mm.Area(blocks).series\n",
    "blocks[\"ldkPer\"] = mm.Perimeter(blocks).series\n",
    "blocks[\"lskCCo\"] = mm.CircularCompactness(blocks, \"ldkAre\").series\n",
    "blocks[\"lskERI\"] = mm.EquivalentRectangularIndex(blocks, \"ldkAre\", \"ldkPer\").series\n",
    "blocks[\"lskCWA\"] = mm.CompactnessWeightedAxis(blocks, \"ldkAre\", \"ldkPer\").series\n",
    "blocks[\"ltkOri\"] = mm.Orientation(blocks, verbose=False).series\n",
    "\n",
    "blocks[\"ltkWNB\"] = mm.Neighbors(blocks, blo_q1, \"bID\", weighted=True, verbose=False).series\n",
    "blocks[\"likWBB\"] = mm.Count(blocks, buildings, \"bID\", \"bID\", weighted=True).series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84edf6",
   "metadata": {},
   "source": [
    "Save data to parquets as a checkpoint backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8990f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.drop(columns='geometry').to_parquet('../data/tess_data.parquet')\n",
    "buildings.drop(columns='geometry').to_parquet('../data/buildings_data.parquet')\n",
    "blocks.drop(columns='geometry').to_parquet('../data/blocks_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8752e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings['ltbIBD'] = mm.MeanInterbuildingDistance(buildings, queen_1, 'uID', queen_3, verbose=False).series\n",
    "buildings['ltcBuA'] = mm.BuildingAdjacency(buildings, queen_3, 'uID', buildings_q1, verbose=False).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation['sicCAR'] = mm.AreaRatio(tessellation, buildings, 'sdcAre', 'sdbAre', 'uID').series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212039d",
   "metadata": {},
   "source": [
    "Save data to parquets and spatial weights matrices to gal files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.drop(columns='geometry').to_parquet('../data/tess_data.parquet')\n",
    "buildings.drop(columns='geometry').to_parquet('../data/buildings_data.parquet')\n",
    "blocks.drop(columns='geometry').to_parquet('../data/blocks_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"sdsLen\"] = mm.Perimeter(streets).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758eb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"sssLin\"] = mm.Linearity(streets).series\n",
    "streets[\"sdsAre\"] = mm.Reached(streets, tessellation, \"nID\", \"nID\", mode=\"sum\", values=\"sdcAre\").series\n",
    "streets[\"sisBpM\"] = mm.Count(streets, buildings, \"nID\", \"nID\", weighted=True).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d790bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.drop(columns='geometry').to_parquet('../data/tess_data.parquet')\n",
    "buildings.drop(columns='geometry').to_parquet('../data/buildings_data.parquet')\n",
    "streets.drop(columns='geometry').to_parquet('../data/streets_data.parquet')\n",
    "blocks.drop(columns='geometry').to_parquet('../data/blocks_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets[\"misRea\"] = mm.Reached(streets, tessellation, \"nID\", \"nID\", spatial_weights=str_q1, mode=\"count\", verbose=False).series\n",
    "streets[\"mdsAre\"] = mm.Reached(streets, tessellation, \"nID\", \"nID\", spatial_weights=str_q1, mode=\"sum\", verbose=False).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = mm.gdf_to_nx(streets.explode())\n",
    "graph = mm.node_degree(graph)\n",
    "graph = mm.subgraph(\n",
    "    graph,\n",
    "    radius=5,\n",
    "    meshedness=True,\n",
    "    cds_length=False,\n",
    "    mode=\"sum\",\n",
    "    degree=\"degree\",\n",
    "    length=\"mm_len\",\n",
    "    mean_node_degree=False,\n",
    "    proportion={0: True, 3: True, 4: True},\n",
    "    cyclomatic=False,\n",
    "    edge_node_ratio=False,\n",
    "    gamma=False,\n",
    "    local_closeness=True,\n",
    "    closeness_weight=\"mm_len\",\n",
    "    verbose=False\n",
    ")\n",
    "graph = mm.cds_length(graph, radius=3, name=\"ldsCDL\", verbose=False)\n",
    "graph = mm.clustering(graph, name=\"xcnSCl\")\n",
    "graph = mm.mean_node_dist(graph, name=\"mtdMDi\", verbose=False)\n",
    "\n",
    "nodes, edges, sw = mm.nx_to_gdf(graph, spatial_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_file(path+'geometry.gpkg', layer=\"nodes\", driver=\"GPKG\")\n",
    "edges.to_file(path+'geometry.gpkg', layer=\"edges\", driver=\"GPKG\")\n",
    "\n",
    "fo = libpysal.io.open(\"../data/nodes.gal\", \"w\")\n",
    "fo.write(sw)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10993804",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_w3 = mm.sw_high(k=3, gdf=edges)\n",
    "edges[\"ldsMSL\"] = mm.SegmentsLength(edges, spatial_weights=edges_w3, mean=True, verbose=False).series\n",
    "\n",
    "edges[\"ldsRea\"] = mm.Reached(edges, tessellation, \"nID\", \"nID\", spatial_weights=edges_w3, verbose=False).series\n",
    "edges[\"ldsRea\"] = mm.Reached(edges, tessellation, \"nID\", \"nID\", spatial_weights=edges_w3, mode=\"sum\", values=\"sdcAre\", verbose=False).series\n",
    "\n",
    "nodes_w5 = mm.sw_high(k=5, weights=sw)\n",
    "nodes[\"lddNDe\"] = mm.NodeDensity(nodes, edges, nodes_w5, verbose=False).series\n",
    "nodes[\"linWID\"] = mm.NodeDensity(nodes, edges, nodes_w5, weighted=True, node_degree=\"degree\", verbose=False).series\n",
    "\n",
    "buildings[\"nodeID\"] = mm.get_node_id(buildings, nodes, edges.drop_duplicates(subset='nID'), \"nodeID\", \"nID\")\n",
    "tessellation = tessellation.merge(buildings[[\"uID\", \"nodeID\"]], on=\"uID\", how=\"left\")\n",
    "\n",
    "nodes_w3 = mm.sw_high(k=3, weights=sw)\n",
    "\n",
    "nodes[\"lddRea\"] = mm.Reached(nodes, tessellation, \"nodeID\", \"nodeID\", nodes_w3, verbose=False).series\n",
    "nodes[\"lddARe\"] = mm.Reached(nodes, tessellation, \"nodeID\", \"nodeID\", nodes_w3, mode=\"sum\", values=\"sdcAre\", verbose=False).series\n",
    "\n",
    "nodes[\"sddAre\"] = mm.Reached(nodes, tessellation, \"nodeID\", \"nodeID\", mode=\"sum\", values=\"sdcAre\", verbose=False).series\n",
    "nodes[\"midRea\"] = mm.Reached(nodes, tessellation, \"nodeID\", \"nodeID\", spatial_weights=sw, verbose=False).series\n",
    "nodes[\"midAre\"] = mm.Reached(nodes, tessellation, \"nodeID\", \"nodeID\", spatial_weights=sw, mode=\"sum\", values=\"sdcAre\", verbose=False).series\n",
    "\n",
    "nodes.rename(\n",
    "    columns={\n",
    "        \"degree\": \"mtdDeg\",\n",
    "        \"meshedness\": \"lcdMes\",\n",
    "        \"local_closeness\": \"lcnClo\",\n",
    "        \"proportion_3\": \"linP3W\",\n",
    "        \"proportion_4\": \"linP4W\",\n",
    "        \"proportion_0\": \"linPDE\",\n",
    "    }, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9529124",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.drop(columns='geometry').to_parquet('../data/tess_data.parquet')\n",
    "buildings.drop(columns='geometry').to_parquet('../data/buildings_data.parquet')\n",
    "blocks.drop(columns='geometry').to_parquet('../data/blocks_data.parquet')\n",
    "nodes.drop(columns='geometry').to_parquet('../data/nodes_data.parquet')\n",
    "edges.drop(columns='geometry').to_parquet('../data/edges_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tessellation.merge(buildings.drop(columns=['nID', 'bID', 'nodeID', 'geometry']), on='uID')\n",
    "merged = merged.merge(blocks.drop(columns='geometry'), on='bID', how='left')\n",
    "merged = merged.merge(edges.drop(columns='geometry'), on='nID', how='left')\n",
    "merged = merged.merge(nodes.drop(columns='geometry'), on='nodeID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e7ef7",
   "metadata": {},
   "source": [
    "Clean columns to keep only measured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = merged.drop(columns=['nID', 'bID', 'eID', 'nodeID', 'mm_len', 'cdsbool', 'node_start', 'node_end', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51938202",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary.to_parquet('../data/primary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a5aa2",
   "metadata": {},
   "source": [
    "## Measure contextual - spatially lagged characters\n",
    "\n",
    "This part measures contextual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = primary.set_index('uID')\n",
    "spatial_weights = queen_3\n",
    "unique_id = 'uID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6371a8",
   "metadata": {},
   "source": [
    "For importing `spatial_weights` from file use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial_weights = libpysal.io.open('../data/queen_3.gal', 'r').read()\n",
    "#spatial_weights.neighbors = {int(float(k)): [int(float(i)) for i in v] for k, v in spatial_weights.neighbors.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815220b",
   "metadata": {},
   "source": [
    "Resolve potential missingness cause by invalid input data. That was not case in the presented case studies but may be case in subsequent research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a696d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.replace(np.inf, np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['lcdMes'] = gdf.apply(lambda row: row.lcdMes if row.lcdMes >= 0 else 0, axis=1)  # normally does not happen, but to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e569bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = list(gdf.index.values)\n",
    "indexes_set = frozenset(indexes)\n",
    "all_indexes = list(range(int(gdf.index.max())))\n",
    "new_indexes = [i for i in all_indexes if i not in indexes_set]\n",
    "gdf = pd.concat([gdf, pd.DataFrame(np.nan, new_indexes, chars)])\n",
    "gdf = gdf.sort_index()\n",
    "ndf = gdf.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db1b0f",
   "metadata": {},
   "source": [
    "Define Theil function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _theil(y):\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "    plus = y + np.finfo('float').tiny * (y == 0)  # can't have 0 values\n",
    "    yt = plus.sum(axis=0)\n",
    "    s = plus / (yt * 1.0)\n",
    "    lns = np.log(n * s)\n",
    "    slns = s * lns\n",
    "    t = sum(slns)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02203f",
   "metadata": {},
   "source": [
    "Loop over DataFrame and measure IQM, IQR and IDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "ranges = []\n",
    "theils = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3180e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_range(subset, rng_min, rng_max):\n",
    "    lower = np.nanpercentile(subset, rng_min)\n",
    "    higher = np.nanpercentile(subset, rng_max)\n",
    "    new = np.where((lower <= subset)&(subset <= higher), subset, np.nan)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ad9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in tqdm(indexes, total=len(indexes)):\n",
    "    \n",
    "    subset = ndf[np.array([int(x) for x in ([index] + spatial_weights.neighbors[index])]), :]\n",
    "    \n",
    "    means.append(np.nanmean(limit_range(subset, 25, 70), axis=0))\n",
    "    ranges.append(np.nanmax(limit_range(subset, 25, 70), axis=0) - np.nanmin(limit_range(subset, 25, 70), axis=0)) \n",
    "    theils.append(_theil(limit_range(subset, 10, 90)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba173b",
   "metadata": {},
   "source": [
    "Get final contextual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = gdf.columns\n",
    "\n",
    "means = pd.DataFrame(means[0:], columns=columns+'_IQM', index=indexes)\n",
    "ranges = pd.DataFrame(ranges[0:], columns=columns+'_IQR', index=indexes)\n",
    "theils = pd.DataFrame(theils[0:], columns=columns+'_IDT', index=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.drop(new_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f455bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual = means_df.join(ranges, how='inner').join(theils, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2caa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual = contextual.dropna(axis=1, how='all')\n",
    "contextual = contextual.dropna(axis=0, how='all')\n",
    "contextual = contextual[~contextual.index.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual.to_parquet('../data/contextual.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3bf04",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "**Note**: This part of work you can handle in [Kaggle](https://www.kaggle.com) which is designed for machine learning purpose.\n",
    "\n",
    "We use contextual characters to do GMM clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = contextual.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b43077",
   "metadata": {},
   "source": [
    "First we standardize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbcf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.values\n",
    "scaler = preprocessing.StandardScaler()\n",
    "cols = list(data.columns)\n",
    "data[cols] = scaler.fit_transform(data[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26e1cc",
   "metadata": {},
   "source": [
    "Measure BIC to estimate optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af53832",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = pd.DataFrame(columns=['n', 'bic', 'run'])\n",
    "ix = 0\n",
    "\n",
    "n_components_range = range(2, 8) # specify range you want to assess\n",
    "gmmruns = 1  # specify how many times should each option be tried (more better, but takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61206c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "for n_components in n_components_range:\n",
    "    for i in range(gmmruns):\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type=\"full\", max_iter=200, n_init=1, verbose=1)\n",
    "        fitted = gmm.fit(data)\n",
    "        bicnum = gmm.bic(data)\n",
    "        bic.loc[ix] = [n_components, bicnum, i]\n",
    "        ix += 1\n",
    "\n",
    "        print(n_components, i, \"BIC:\", bicnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic.to_csv('../data/complete_BIC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67540334",
   "metadata": {},
   "source": [
    "Based on the plot below, we estimate the optimal `n` either based on the elbow of the curve or as the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "sns.lineplot(ax=ax, x='n', y='bic', data=bic)\n",
    "plt.savefig('../data/complete_BIC.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ed96c",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98525ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5 # illustrative - always base the number on a reasonable estimation of the optimal number of components\n",
    "n_init = 1  # more initialization, more stable clustering gets\n",
    "\n",
    "gmm = GaussianMixture(n_components=n, covariance_type=\"full\", max_iter=200, n_init=n_init, verbose=1)\n",
    "fitted = gmm.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c79151",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gmm.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66400bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(labels, index=data.index).to_csv('../data/cluster_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8d3ee",
   "metadata": {},
   "source": [
    "#### Hierachical clustering\n",
    "\n",
    "Finally, we create hierarchical classification - taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdade6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby(labels).mean()\n",
    "Z = hierarchy.linkage(group, 'ward')\n",
    "plt.figure(figsize=(16, 9))\n",
    "dn = hierarchy.dendrogram(Z, labels=group.index)\n",
    "\n",
    "plt.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83cd82",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(labels, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = buildings.set_index('uID')\n",
    "buildings = buildings.join(final)\n",
    "buildings = buildings.rename(columns={0: 'Class'})\n",
    "buildings = buildings.drop(columns=['nID', 'bID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.to_file('../data/buildings_labels.gpkg', layer='buildings', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation = tessellation.set_index('uID')\n",
    "tessellation = tessellation.join(final)\n",
    "tessellation = tessellation.rename(columns={0: 'Class'})\n",
    "tessellation = tessellation.drop(columns=['nID', 'bID', 'eID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd24df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tessellation.to_file('../data/tessellation_labels.gpkg', layer='tessellation', driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
